<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="IPython Books, ">


    <!-- FAVICON -->
    <link rel="apple-touch-icon" sizes="57x57" href="/apple-touch-icon-57x57.png">
    <link rel="apple-touch-icon" sizes="114x114" href="/apple-touch-icon-114x114.png">
    <link rel="apple-touch-icon" sizes="72x72" href="/apple-touch-icon-72x72.png">
    <link rel="apple-touch-icon" sizes="144x144" href="/apple-touch-icon-144x144.png">
    <link rel="apple-touch-icon" sizes="60x60" href="/apple-touch-icon-60x60.png">
    <link rel="apple-touch-icon" sizes="120x120" href="/apple-touch-icon-120x120.png">
    <link rel="apple-touch-icon" sizes="76x76" href="/apple-touch-icon-76x76.png">
    <link rel="apple-touch-icon" sizes="152x152" href="/apple-touch-icon-152x152.png">
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon-180x180.png">
    <link rel="icon" type="image/png" href="/favicon-192x192.png" sizes="192x192">
    <link rel="icon" type="image/png" href="/favicon-160x160.png" sizes="160x160">
    <link rel="icon" type="image/png" href="/favicon-96x96.png" sizes="96x96">
    <link rel="icon" type="image/png" href="/favicon-16x16.png" sizes="16x16">
    <link rel="icon" type="image/png" href="/favicon-32x32.png" sizes="32x32">
    <meta name="msapplication-TileColor" content="#da532c">
    <meta name="msapplication-TileImage" content="/mstile-144x144.png">


        <link rel="alternate"  href="http://ipython-books.github.io/feeds/atom.xml" type="application/atom+xml" title="IPython Books Full Atom Feed"/>
        <link rel="alternate" href="http://ipython-books.github.io/feeds/rss.xml" type="application/rss+xml" title="IPython Books Full RSS Feed"/>

        <title>IPython Books - Featured Recipe #1: Getting the Best Performance out of NumPy</title>

    <link href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.2.0/css/font-awesome.min.css" rel="stylesheet">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/pure/0.3.0/pure-min.css">
    <!--[if lte IE 8]>
        <link rel="stylesheet" href="http://yui.yahooapis.com/pure/0.5.0/grids-responsive-old-ie-min.css">
    <![endif]-->
    <!--[if gt IE 8]><!-->
        <link rel="stylesheet" href="http://yui.yahooapis.com/pure/0.5.0/grids-responsive-min.css">
    <!--<![endif]-->
    <link rel="stylesheet" href="http://ipython-books.github.io/theme/css/styles.css">
    <link rel="stylesheet" href="http://ipython-books.github.io/theme/css/pygments.css">
    <!-- <link href='http://fonts.googleapis.com/css?family=Lato:300,400,700' rel='stylesheet' type='text/css'> -->
    <link href="http://fonts.googleapis.com/css?family=Source+Sans+Pro:300,500" rel="stylesheet" type="text/css">
    <link href='http://fonts.googleapis.com/css?family=Ubuntu+Mono' rel='stylesheet' type='text/css'>
    

    <script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>
</head>

<body>


    <header id="header" class="pure-g">
        <div class="pure-u-1 pure-u-md-3-4">
             <div id="menu">
                 <div class="pure-menu pure-menu-open pure-menu-horizontal">
<ul>
        <li><a href="/">Home</a></li>
        <li><a href="/minibook/">Minibook</a></li>
        <li><a href="/cookbook/">Cookbook</a></li>
        <li><a href="http://cyrille.rossant.net">Author</a></li>
</ul>                </div>
            </div>
        </div>

        <div class="pure-u-1 pure-u-md-1-4">
            <div id="social">
                <div class="pure-menu pure-menu-open pure-menu-horizontal">
<ul>
        <li><a href="https://twitter.com/cyrillerossant"><i class="fa fa-twitter"></i></a></li>
        <li><a href="https://github.com/ipython-books"><i class="fa fa-github"></i></a></li>
        <li><a href="/feeds/atom.xml"><i class="fa fa-rss"></i></a></li>
</ul>                </div>
            </div>
        </div>
    </header>
       

    
    <div id="layout" class="pure-g">
        <section id="content" class="pure-u-1 pure-u-md-3-4">
            <div class="l-box">

    <header id="page-header">
        <h1>Featured Recipe #1: Getting the Best Performance out of NumPy</h1>
    </header>

    <section id="page">
        <blockquote>
<p>This is the first featured recipe from the <a href="http://ipython-books.github.io/"><strong>IPython Cookbook</strong></a>, the definitive guide to <strong>high-performance scientific computing</strong> and <strong>data science</strong> in Python.</p>
</blockquote>
<p><strong>NumPy</strong> is the cornerstone of the scientific Python software stack. It provides a special data type optimized for vector computations, the <code>ndarray</code>. This object is at the core of most algorithms in scientific numerical computing.</p>
<p>With NumPy arrays, you can achieve significant performance speedups over native Python, particularly when your computations follow the <strong><em>Single Instruction, Multiple Data</em> (SIMD)</strong> paradigm. However, it is also possible to unintentionally write non-optimized code with NumPy.</p>
<p>In this featured recipe, we will see some tricks that can help you write optimized NumPy code. We will start by looking at ways to avoid unnecessary array copies in order to save time and memory. In that respect, we will need to dig into the internals of NumPy.</p>
<h2>Learning to avoid unnecessary array copies</h2>
<p>Computations with NumPy arrays may involve internal copies between blocks of memory. These copies are not always necessary, in which case they should be avoided. Here are a few tips that can help you optimize your code accordingly.</p>
<div class="ipynb-input"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
</pre></div>
</div>

<h3>Inspect the memory address of arrays</h3>
<ol>
<li>The first step when looking for silent array copies is to find out the location of arrays in memory. The following function does just that:</li>
</ol>
<div class="ipynb-input"><div class="highlight"><pre><span class="k">def</span> <span class="nf">id</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="c"># This function returns the memory</span>
    <span class="c"># block address of an array.</span>
    <span class="k">return</span> <span class="n">x</span><span class="o">.</span><span class="n">__array_interface__</span><span class="p">[</span><span class="s">&#39;data&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>

<ol>
<li>You may sometimes need to make a copy of an array, for instance if you need to manipulate an array while keeping an original copy in memory.</li>
</ol>
<div class="ipynb-input"><div class="highlight"><pre><span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">10</span><span class="p">);</span> <span class="n">aid</span> <span class="o">=</span> <span class="nb">id</span><span class="p">(</span><span class="n">a</span><span class="p">);</span> <span class="n">aid</span>
</pre></div>
</div>

<pre class="ipynb-output">71211328</pre>

<div class="ipynb-input"><div class="highlight"><pre><span class="n">b</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">copy</span><span class="p">();</span> <span class="nb">id</span><span class="p">(</span><span class="n">b</span><span class="p">)</span> <span class="o">==</span> <span class="n">aid</span>
</pre></div>
</div>

<pre class="ipynb-output">False</pre>

<p>Two arrays with the same data location (as returned by <code>id</code>) share the underlying data buffer. However, the opposite is only true if the arrays have the same <strong>offset</strong> (meaning that they have the same first element). Two shared arrays with different offsets will have slightly different memory locations, as shown in the following example:</p>
<div class="ipynb-input"><div class="highlight"><pre><span class="nb">id</span><span class="p">(</span><span class="n">a</span><span class="p">),</span> <span class="nb">id</span><span class="p">(</span><span class="n">a</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
</pre></div>
</div>

<pre class="ipynb-output">(71211328, 71211336)</pre>

<p>In this recipe, we'll make sure to use this method with arrays that have the same offset. Here is a more reliable solution for finding out if two arrays share the same data:</p>
<div class="ipynb-input"><div class="highlight"><pre><span class="k">def</span> <span class="nf">get_data_base</span><span class="p">(</span><span class="n">arr</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;For a given Numpy array, finds the</span>
<span class="sd">    base array that &quot;owns&quot; the actual data.&quot;&quot;&quot;</span>
    <span class="n">base</span> <span class="o">=</span> <span class="n">arr</span>
    <span class="k">while</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">base</span><span class="o">.</span><span class="n">base</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
        <span class="n">base</span> <span class="o">=</span> <span class="n">base</span><span class="o">.</span><span class="n">base</span>
    <span class="k">return</span> <span class="n">base</span>

<span class="k">def</span> <span class="nf">arrays_share_data</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">get_data_base</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="ow">is</span> <span class="n">get_data_base</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>

</div>

<div class="ipynb-input"><div class="highlight"><pre><span class="k">print</span><span class="p">(</span><span class="n">arrays_share_data</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">a</span><span class="o">.</span><span class="n">copy</span><span class="p">()),</span>
      <span class="n">arrays_share_data</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">a</span><span class="p">[</span><span class="mi">1</span><span class="p">:]))</span>
</pre></div>
</div>

<pre class="ipynb-output">False True</pre>

<p>Thanks to <a href="https://github.com/ipython-books/cookbook-code/issues/2">Michael Droettboom</a> for pointing out this precision and proposing this alternative solution.</p>
<h3>In-place and implicit copy operations</h3>
<ol>
<li>Array computations can involve in-place operations (first example below: the array is modified) or implicit-copy operations (second example: a new array is created).</li>
</ol>
<div class="ipynb-input"><div class="highlight"><pre><span class="n">a</span> <span class="o">*=</span> <span class="mi">2</span><span class="p">;</span> <span class="nb">id</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="o">==</span> <span class="n">aid</span>
</pre></div>
</div>

<pre class="ipynb-output">True</pre>

<div class="ipynb-input"><div class="highlight"><pre><span class="n">c</span> <span class="o">=</span> <span class="n">a</span> <span class="o">*</span> <span class="mi">2</span><span class="p">;</span> <span class="nb">id</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="o">==</span> <span class="n">aid</span>
</pre></div>
</div>

<pre class="ipynb-output">False</pre>

<p>Be sure to choose the type of operation you actually need. Implicit-copy operations are significantly slower, as shown here:</p>
<div class="ipynb-input"><div class="highlight"><pre><span class="o">%%</span><span class="n">timeit</span> <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">10000000</span><span class="p">)</span>
<span class="n">a</span> <span class="o">*=</span> <span class="mi">2</span>
</pre></div>
</div>

<pre class="ipynb-output">10 loops, best of 3: 19.2 ms per loop</pre>

<div class="ipynb-input"><div class="highlight"><pre><span class="o">%%</span><span class="n">timeit</span> <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">10000000</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">a</span> <span class="o">*</span> <span class="mi">2</span>
</pre></div>
</div>

<pre class="ipynb-output">10 loops, best of 3: 42.6 ms per loop</pre>

<ol>
<li>Reshaping an array may or may not involve a copy. The reasons will be explained below. For instance, reshaping a 2D matrix does not involve a copy, unless it is transposed (or more generally non-contiguous):</li>
</ol>
<div class="ipynb-input"><div class="highlight"><pre><span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">));</span> <span class="n">aid</span> <span class="o">=</span> <span class="nb">id</span><span class="p">(</span><span class="n">a</span><span class="p">);</span> <span class="n">aid</span>
</pre></div>
</div>

<pre class="ipynb-output">53423728</pre>

<p>Reshaping an array while preserving its order does not trigger a copy.</p>
<div class="ipynb-input"><div class="highlight"><pre><span class="n">b</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">));</span> <span class="nb">id</span><span class="p">(</span><span class="n">b</span><span class="p">)</span> <span class="o">==</span> <span class="n">aid</span>
</pre></div>
</div>

<pre class="ipynb-output">True</pre>

<p>Transposing an array changes its order so that a reshape triggers a copy.</p>
<div class="ipynb-input"><div class="highlight"><pre><span class="n">c</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">));</span> <span class="nb">id</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="o">==</span> <span class="n">aid</span>
</pre></div>
</div>

<pre class="ipynb-output">False</pre>

<p>Therefore, the latter instruction will be significantly slower than the former.</p>
<ol>
<li>The flatten and ravel methods of an array reshape it into a 1D vector (flattened array). The former method always returns a copy, whereas the latter returns a copy only if necessary (so it's significantly faster too, especially with large arrays).</li>
</ol>
<div class="ipynb-input"><div class="highlight"><pre><span class="n">d</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">flatten</span><span class="p">();</span> <span class="nb">id</span><span class="p">(</span><span class="n">d</span><span class="p">)</span> <span class="o">==</span> <span class="n">aid</span>
</pre></div>
</div>

<pre class="ipynb-output">False</pre>

<div class="ipynb-input"><div class="highlight"><pre><span class="n">e</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">ravel</span><span class="p">();</span> <span class="nb">id</span><span class="p">(</span><span class="n">e</span><span class="p">)</span> <span class="o">==</span> <span class="n">aid</span>
</pre></div>
</div>

<pre class="ipynb-output">True</pre>

<div class="ipynb-input"><div class="highlight"><pre><span class="o">%</span><span class="n">timeit</span> <span class="n">a</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
</pre></div>
</div>

<pre class="ipynb-output">1000000 loops, best of 3: 881 ns per loop</pre>

<div class="ipynb-input"><div class="highlight"><pre><span class="o">%</span><span class="n">timeit</span> <span class="n">a</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
</pre></div>
</div>

<pre class="ipynb-output">1000000 loops, best of 3: 294 ns per loop</pre>

<h3>Broadcasting rules</h3>
<ol>
<li><strong>Broadcasting rules</strong> allow you to make computations on arrays with different but compatible shapes. In other words, you don't always need to reshape or tile your arrays to make their shapes match. The following example illustrates two ways of doing an outer product between two vectors: the first method involves array tiling, the second one involves broadcasting. The last method is significantly faster.</li>
</ol>
<div class="ipynb-input"><div class="highlight"><pre><span class="n">n</span> <span class="o">=</span> <span class="mi">1000</span>
</pre></div>
</div>

<div class="ipynb-input"><div class="highlight"><pre><span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
<span class="n">ac</span> <span class="o">=</span> <span class="n">a</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
<span class="n">ar</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="p">:]</span>
</pre></div>
</div>

<div class="ipynb-input"><div class="highlight"><pre><span class="o">%</span><span class="n">timeit</span> <span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">ac</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">ar</span><span class="p">,</span> <span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>

<pre class="ipynb-output">100 loops, best of 3: 10 ms per loop</pre>

<div class="ipynb-input"><div class="highlight"><pre><span class="o">%</span><span class="n">timeit</span> <span class="n">ar</span> <span class="o">*</span> <span class="n">ac</span>
</pre></div>
</div>

<pre class="ipynb-output">100 loops, best of 3: 2.36 ms per loop</pre>

<h2>Making efficient selections in arrays with NumPy</h2>
<p>NumPy offers multiple ways of selecting slices of arrays. Array views refer to the original data buffer of an array, but with different offsets, shapes and strides. They only permit strided selections (i.e. with linearly spaced indices). NumPy also offers specific functions to make arbitrary selections along one axis. Finally, fancy indexing is the most general selection method, but it is also the slowest as we will see in this recipe. Faster alternatives should be chosen when possible.</p>
<ol>
<li>Let's create an array with a large number of rows. We will select slices of this array along the first dimension.</li>
</ol>
<div class="ipynb-input"><div class="highlight"><pre><span class="n">n</span><span class="p">,</span> <span class="n">d</span> <span class="o">=</span> <span class="mi">100000</span><span class="p">,</span> <span class="mi">100</span>
</pre></div>
</div>

<div class="ipynb-input"><div class="highlight"><pre><span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random_sample</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="n">d</span><span class="p">));</span> <span class="n">aid</span> <span class="o">=</span> <span class="nb">id</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
</pre></div>
</div>

<h3>Array views and fancy indexing</h3>
<ol>
<li>Let's select one every ten rows, using two different methods (array view and fancy indexing).</li>
</ol>
<div class="ipynb-input"><div class="highlight"><pre><span class="n">b1</span> <span class="o">=</span> <span class="n">a</span><span class="p">[::</span><span class="mi">10</span><span class="p">]</span>
<span class="n">b2</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="mi">10</span><span class="p">)]</span>
</pre></div>
</div>

<div class="ipynb-input"><div class="highlight"><pre><span class="n">np</span><span class="o">.</span><span class="n">array_equal</span><span class="p">(</span><span class="n">b1</span><span class="p">,</span> <span class="n">b2</span><span class="p">)</span>
</pre></div>
</div>

<pre class="ipynb-output">True</pre>

<ol>
<li>The view refers to the original data buffer, whereas fancy indexing yields a copy.</li>
</ol>
<div class="ipynb-input"><div class="highlight"><pre><span class="nb">id</span><span class="p">(</span><span class="n">b1</span><span class="p">)</span> <span class="o">==</span> <span class="n">aid</span><span class="p">,</span> <span class="nb">id</span><span class="p">(</span><span class="n">b2</span><span class="p">)</span> <span class="o">==</span> <span class="n">aid</span>
</pre></div>
</div>

<pre class="ipynb-output">(True, False)</pre>

<ol>
<li>Let's compare the performance of both methods.</li>
</ol>
<div class="ipynb-input"><div class="highlight"><pre><span class="o">%</span><span class="n">timeit</span> <span class="n">a</span><span class="p">[::</span><span class="mi">10</span><span class="p">]</span>
</pre></div>
</div>

<pre class="ipynb-output">1000000 loops, best of 3: 804 ns per loop</pre>

<div class="ipynb-input"><div class="highlight"><pre><span class="o">%</span><span class="n">timeit</span> <span class="n">a</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="mi">10</span><span class="p">)]</span>
</pre></div>
</div>

<pre class="ipynb-output">100 loops, best of 3: 14.1 ms per loop</pre>

<p>Fancy indexing is several orders of magnitude slower as it involves copying a large array.</p>
<h3>Alternatives to fancy indexing: list of indices</h3>
<ol>
<li>When non-strided selections need to be done along one dimension, array views are not an option. However, alternatives to fancy indexing still exist in this case. Given a list of indices, NumPy's function take performs a selection along one axis.</li>
</ol>
<div class="ipynb-input"><div class="highlight"><pre><span class="n">i</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>

<div class="ipynb-input"><div class="highlight"><pre><span class="n">b1</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
<span class="n">b2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>

<div class="ipynb-input"><div class="highlight"><pre><span class="n">np</span><span class="o">.</span><span class="n">array_equal</span><span class="p">(</span><span class="n">b1</span><span class="p">,</span> <span class="n">b2</span><span class="p">)</span>
</pre></div>
</div>

<pre class="ipynb-output">True</pre>

<p>The second method is faster:</p>
<div class="ipynb-input"><div class="highlight"><pre><span class="o">%</span><span class="n">timeit</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</pre></div>
</div>

<pre class="ipynb-output">100 loops, best of 3: 13 ms per loop</pre>

<div class="ipynb-input"><div class="highlight"><pre><span class="o">%</span><span class="n">timeit</span> <span class="n">np</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>

<pre class="ipynb-output">100 loops, best of 3: 4.87 ms per loop</pre>

<h3>Alternatives to fancy indexing: mask of booleans</h3>
<ol>
<li>When the indices to select along one axis are specified by a vector of boolean masks, the function <code>compress</code> is an alternative to fancy indexing.</li>
</ol>
<div class="ipynb-input"><div class="highlight"><pre><span class="n">i</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random_sample</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="o">&lt;</span> <span class="o">.</span><span class="mi">5</span>
</pre></div>
</div>

<p>The selection can be made using fancy indexing or the <code>np.compress</code> function.</p>
<div class="ipynb-input"><div class="highlight"><pre><span class="n">b1</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
<span class="n">b2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">compress</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>

<div class="ipynb-input"><div class="highlight"><pre><span class="n">np</span><span class="o">.</span><span class="n">array_equal</span><span class="p">(</span><span class="n">b1</span><span class="p">,</span> <span class="n">b2</span><span class="p">)</span>
</pre></div>
</div>

<pre class="ipynb-output">True</pre>

<div class="ipynb-input"><div class="highlight"><pre><span class="o">%</span><span class="n">timeit</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</pre></div>
</div>

<pre class="ipynb-output">10 loops, best of 3: 59.8 ms per loop</pre>

<div class="ipynb-input"><div class="highlight"><pre><span class="o">%</span><span class="n">timeit</span> <span class="n">np</span><span class="o">.</span><span class="n">compress</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>

<pre class="ipynb-output">10 loops, best of 3: 24.1 ms per loop</pre>

<p>The second method is also significantly faster than fancy indexing.</p>
<p>Fancy indexing is the most general way of making completely arbitrary selections of an array. However, more specific and faster methods often exist and should be preferred when possible.</p>
<p>Array views should be used whenever strided selections have to be done, but one needs to be careful about the fact that views refer to the original data buffer.</p>
<h2>How it works?</h2>
<p>In this section, we will see what happens under the hood when using NumPy, and how this knowledge allows us to understand the tricks given in this recipe.</p>
<h3>Why are NumPy arrays efficient?</h3>
<p>A NumPy array is basically described by metadata (number of dimensions, shape, data type, and so on) and the actual data. The data is stored in a homogeneous and contiguous block of memory, at a particular address in system memory (<em>Random Access Memory</em>, or RAM). This block of memory is called the <strong>data buffer</strong>. This is the main difference with a pure Python structure, like a list, where the items are scattered across the system memory. This aspect is the critical feature that makes NumPy arrays so efficient.</p>
<p>Why is this so important? Here are the main reasons:</p>
<ol>
<li>
<p><strong>Array computations can be written very efficiently in a low-level language like C</strong> (and a large part of NumPy is actually written in C). Knowing the address of the memory block and the data type, it is just simple arithmetic to loop over all items, for example. There would be a significant overhead to do that in Python with a list.</p>
</li>
<li>
<p><strong>Spatial locality in memory access patterns</strong> results in significant performance gains, notably thanks to the CPU cache. Indeed, the cache loads bytes in chunks from RAM to the CPU registers. Adjacent items are then loaded very efficiently (sequential locality, or locality of reference).</p>
</li>
<li>
<p><strong>Data elements are stored contiguously in memory</strong>, so that NumPy can take advantage of vectorized instructions on modern CPUs, like Intel's SSE and AVX, AMD's XOP, and so on. For example, multiple consecutive floating point numbers can be loaded in 128, 256 or 512 bits registers for vectorized arithmetical computations implemented as CPU instructions.</p>
</li>
</ol>
<p>Additionally, let's mention the fact that NumPy can be linked to highly optimized linear algebra libraries like <em>BLAS</em> and <em>LAPACK</em>, for example through the <em>Intel Math Kernel Library (MKL)</em>. A few specific matrix computations may also be multithreaded, taking advantage of the power of modern multicore processors.</p>
<p>In conclusion, <strong>storing data in a contiguous block of memory ensures that the architecture of modern CPUs is used optimally, in terms of memory access patterns, CPU cache, and vectorized instructions</strong>.</p>
<h3>What is the difference between in-place and implicit-copy operations?</h3>
<p>Let's explain trick 3. An expression like <code>a *= 2</code> corresponds to an in-place operation, where all values of the array are multiplied by two. By contrast, <code>a = a * 2</code> means that a new array containing the values of <code>a * 2</code> is created, and the variable a now points to this new array. The old array becomes unreferenced and will be deleted by the garbage collector. No memory allocation happens in the first case, contrary to the second case.</p>
<p>More generally, expressions like <code>a[i:j]</code> are views to parts of an array: they point to the memory buffer containing the data. Modifying them with in-place operations changes the original array. Hence, <code>a[:] = a * 2</code> results in an in-place operation, unlike <code>a = a * 2</code>.</p>
<p>Knowing this subtlety of NumPy can help you fix some bugs (where an array is implicitly and unintentionally modified because of an operation on a view), and optimize the speed and memory consumption of your code by reducing the number of unnecessary copies.</p>
<h3>Why cannot some arrays be reshaped without a copy?</h3>
<p>We explain here trick 4, where a transposed 2D matrix cannot be flattened without a copy. A 2D matrix contains items indexed by two numbers (row and column), but it is stored internally as a 1D contiguous block of memory, accessible with a single number. There is more than one way of storing matrix items in a 1D block of memory: we can put the elements of the first row first, the second row then, and so on, or the elements of the first column first, the second column then, and so on. The first method is called row-major order, whereas the latter is called column-major order. Choosing between the two methods is only a matter of internal convention: NumPy uses the row-major order, like C, but unlike FORTRAN.</p>
<p><img alt="Array layout" src="/images/layout.png" /></p>
<p>More generally, NumPy uses the notion of <strong>strides</strong> to convert between a multidimensional index and the memory location of the underlying (1D) sequence of elements. The specific mapping between <code>array[i1, i2]</code> and the relevant byte address of the internal data is given by</p>
<p><code>offset = array.strides[0] * i1 + array.strides[1] * i2</code></p>
<p>When reshaping an array, NumPy avoids copies when possible by modifying the <code>strides</code> attribute. For example, when transposing a matrix, the order of <code>strides</code> is reversed, but the underlying data remains identical. However, flattening a transposed array cannot be accomplished simply by modifying <code>strides</code> (try it!), so a copy is needed (thanks to <a href="http://chrisbeaumont.org/">Chris Beaumont</a> from Harvard for clarifying an earlier version of this paragraph).</p>
<p><a href="http://nbviewer.ipython.org/github/ipython-books/cookbook-code/blob/master/notebooks/chapter04_optimization/06_stride_tricks.ipynb">Recipe 4.6</a> (<em>Using stride tricks with NumPy</em>) contains a more extensive discussion on strides. Also, <a href="http://nbviewer.ipython.org/github/ipython-books/cookbook-code/blob/master/notebooks/chapter04_optimization/07_rolling_average.ipynb">recipe 4.7</a> (<em>Implementing an efficient rolling average algorithm with stride tricks</em>) shows how one can use strides to accelerate particular array computations.</p>
<p>Internal array layout can also explain some unexpected performance discrepancies between very similar NumPy operations. As a small exercise, can you explain the following benchmarks?</p>
<div class="ipynb-input"><div class="highlight"><pre><span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">5000</span><span class="p">,</span> <span class="mi">5000</span><span class="p">)</span>
<span class="o">%</span><span class="n">timeit</span> <span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">,:]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="o">%</span><span class="n">timeit</span> <span class="n">a</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>

<pre class="ipynb-output">100000 loops, best of 3: 9.57 µs per loop
10000 loops, best of 3: 68.3 µs per loop</pre>

<h3>What are NumPy broadcasting rules?</h3>
<p>Broadcasting rules describe how arrays with different dimensions and/or shapes can still be used for computations. The general rule is that two dimensions are compatible when they are equal, or when one of them is 1. NumPy uses this rule to compare the shapes of the two arrays element-wise, starting with the trailing dimensions and working its way forward. The smallest dimension is internally stretched to match the other dimension, but this operation does not involve any memory copy.</p>
<h2>References</h2>
<p>Here are a few references:</p>
<ul>
<li><a href="http://cyrille.rossant.net/numpy-performance-tricks/">NumPy performance tricks</a>.</li>
<li><a href="http://en.wikipedia.org/wiki/Locality_of_reference">Locality of reference</a>.</li>
<li><a href="http://scipy-lectures.github.io/advanced/advanced_numpy/">Internals of NumPy in the SciPy lectures notes</a>.</li>
<li><a href="http://www.loria.fr/~rougier/teaching/numpy.100/index.html">100 NumPy exercices</a>.</li>
<li><a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">Broadcasting rules and examples</a>.</li>
<li><a href="http://docs.scipy.org/doc/numpy/reference/arrays.interface.html">Array interface in NumPy</a>.</li>
<li><a href="http://docs.scipy.org/doc/numpy/reference/">The complete list of NumPy routines is available on the NumPy Reference Guide</a>.</li>
<li><a href="http://docs.scipy.org/doc/numpy/reference/routines.indexing.html">List of indexing routines</a>.</li>
</ul>
<p>You will find related recipes on the <a href="https://github.com/ipython-books/cookbook-code">book's repository</a>.</p>
<blockquote>
<p>This was a featured recipe from the <a href="http://ipython-books.github.io/">IPython Cookbook</a>, by <a href="http://cyrille.rossant.net">Cyrille Rossant</a>, Packt Publishing, 2014.</p>
</blockquote>
    </section>

            </div>
        </section>
        
        <nav id="sidebar" class="pure-u-1 pure-u-md-1-4">
            <div class="l-box">

<section class="books">
	<div class="book-1">
		<div class="box">
			<a href="/minibook/"><img src="/images/minibook.jpg"/></a>
	    </div>
	</div>
	<div class="book-2">
		<div class="box">
			<a href="/cookbook/"><img src="/images/cookbook.jpg"/></a>
	    </div>
	</div>
	<p>
		Two books on <strong>Python for data science</strong>, by <a href="http://cyrille.rossant.net">Cyrille Rossant</a>.
	</p>
	<div class="book-1">
		<div class="box">
			<p>beginner-level</p>
			<a href="https://github.com/ipython-books/minibook-code"><button class="button-book1 button-code pure-button">
				<i class="fa fa-code"></i>&nbsp;&nbsp;&nbsp;code
			</button></a>
			<a href="https://github.com/ipython-books/minibook-data"><button class="button-book1 button-data pure-button">
				<i class="fa fa-database"></i>&nbsp;&nbsp;&nbsp;data
			</button></a>
	    </div>
	</div>
	<div class="book-2">
		<div class="box">
			<p>advanced-level</p>
			<a href="https://github.com/ipython-books/cookbook-code"><button class="button-book2 button-code pure-button">
				<i class="fa fa-code"></i>&nbsp;&nbsp;&nbsp;code
			</button></a>
			<a href="https://github.com/ipython-books/cookbook-data"><button class="button-book2 button-data pure-button">
				<i class="fa fa-database"></i>&nbsp;&nbsp;&nbsp;data
			</button></a>
	    </div>
	</div>
</section>            </div>
        </nav>
        
        <footer id="footer" class="pure-u-1 pure-u-md-3-4">
            <div class="l-box">
                <div>
                    <p>&copy; <a href="http://cyrille.rossant.net">Cyrille Rossant</a> &ndash;
                        Built with <a href="https://github.com/PurePelicanTheme/pure-single">Pure Theme</a>
                        for <a href="http://blog.getpelican.com/">Pelican</a>
                    </p>
                </div>
            </div>
        </footer>
        
    </div>
    
<!-- Start of StatCounter Code for Default Guide -->
<script type="text/javascript">
var sc_project=9752080; 
var sc_invisible=1; 
var sc_security="837928c1"; 
var scJsHost = (("https:" == document.location.protocol) ?
"https://secure." : "http://www.");
document.write("<sc"+"ript type='text/javascript' src='" +
scJsHost+
"statcounter.com/counter/counter.js'></"+"script>");
</script>
<noscript><div class="statcounter"><a title="hit counter"
href="http://statcounter.com/free-hit-counter/"
target="_blank"><img class="statcounter"
src="http://c.statcounter.com/9752080/0/837928c1/1/"
alt="hit counter"></a></div></noscript>
<!-- End of StatCounter Code for Default Guide -->
</body>
</html>

